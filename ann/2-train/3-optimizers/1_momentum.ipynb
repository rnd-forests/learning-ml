{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://distill.pub/2017/momentum/\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Moving_average\n",
    "\n",
    "Gradient Descent takes small regular steps down the slope, so it'll take a lot of time to reach the minumum. Gradient Descent updates the weights $\\theta$ by subtracting the gradient of the cost function $J(\\theta)$ with respect to the weights multiplied by the learning rate. Note that Gradient Descent pays no attention to the previous gradients. If the local gradient is small, Gradient Descent goes very slowly.\n",
    "\n",
    "Momentum optimization, on the other hand, pays a great attention to previous gradients. At each iteration, it maintains a momentum vector $m$ by adding local gradients to this vector. At each iteration, it subtracts the local gradient (multiplied by the learning rate) from the vector $m$. It then updates the weights by adding this momentum vector to the current weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAABfCAIAAADqEKLNAAAAA3NCSVQICAjb4U/gAAAAGXRFWHRT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\n5P8lYj/jKiMVOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/momentum.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Momentum optimization, the gradient is used as an acceleration not a speed.\n",
    "\n",
    "To prevent the momentum from growing too large, we use a hyperparameter $\\beta$ (called momentum) which receives a value between 0 and 1 (generally $\\beta$ is set to 0.9). If $\\beta$ is equal to 0, then Momentum becomes the normal Gradient Descent (high friction). If $\\beta$ is close to 1 (no friction), then Momentum goes much faster than normal Gradient Descent.\n",
    "\n",
    "If the gradient remains constant, the terminal velocity is equal to $(1 \\space / \\space (1 \\space - \\space \\beta)) \\space * \\space \\eta \\nabla_\\theta J(\\theta)$. If $\\beta$ = 0.9, the terminal velocity is equal to $10 \\space * \\space \\eta \\nabla_\\theta J(\\theta)$, Momentum optimization would go 10 times faster than Gradient Descent (1000 times if $\\beta = 0.999$). This characteristic allows Momentum optimization to escape from plateaus much faster than Gradient Descent.\n",
    "\n",
    "When input features have very different scales (the cost looks like a elongated bowl), Gradient Descent goes down the steep slope quite fast, but it's very slow when going down the valley. Momentum, on the other hand, can accelerate itself when going to the bottom of valley (the optimum).\n",
    "\n",
    "In DNN which doesn't use Batch Normalization, the upper layers often end up having inputs with very different scales, using Momentum can be a solution for this problem (it can also escapes the local minimum)\n",
    "\n",
    "Momentum optimization may overshoot multiple times through its steps (like pendulum oscillation) before stabilizing at the minimum. That's why we use $\\beta$ hyperparameter to introduce a bit of friction in the system to reduce the overshooting duration and speed up convergence.\n",
    "\n",
    "A drawback of Momentum optimization is that it introduces a new hyperparameter - $\\beta$ for tuning. However, in real-life problems this value is usually set to 0.9, and it works well in lots of problems. Generally, Momentum optimization is faster when reaching to the minimum than Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_inputs = 784\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.elu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xen = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xen, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    # Using Momentum optimizer rather than Gradient Descent optimizer\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0 Test accuracy: 0.8892\n",
      "1 Test accuracy: 0.9034\n",
      "2 Test accuracy: 0.9158\n",
      "3 Test accuracy: 0.9196\n",
      "4 Test accuracy: 0.9241\n",
      "5 Test accuracy: 0.9259\n",
      "6 Test accuracy: 0.9303\n",
      "7 Test accuracy: 0.9382\n",
      "8 Test accuracy: 0.9368\n",
      "9 Test accuracy: 0.9418\n",
      "10 Test accuracy: 0.9428\n",
      "11 Test accuracy: 0.9456\n",
      "12 Test accuracy: 0.9462\n",
      "13 Test accuracy: 0.9505\n",
      "14 Test accuracy: 0.9524\n",
      "15 Test accuracy: 0.9512\n",
      "16 Test accuracy: 0.9552\n",
      "17 Test accuracy: 0.9562\n",
      "18 Test accuracy: 0.9582\n",
      "19 Test accuracy: 0.9601\n",
      "20 Test accuracy: 0.9606\n",
      "21 Test accuracy: 0.96\n",
      "22 Test accuracy: 0.9599\n",
      "23 Test accuracy: 0.9596\n",
      "24 Test accuracy: 0.9638\n",
      "25 Test accuracy: 0.9641\n",
      "26 Test accuracy: 0.9616\n",
      "27 Test accuracy: 0.9642\n",
      "28 Test accuracy: 0.9657\n",
      "29 Test accuracy: 0.9653\n",
      "30 Test accuracy: 0.9648\n",
      "31 Test accuracy: 0.9655\n",
      "32 Test accuracy: 0.9669\n",
      "33 Test accuracy: 0.9664\n",
      "34 Test accuracy: 0.9674\n",
      "35 Test accuracy: 0.9663\n",
      "36 Test accuracy: 0.9685\n",
      "37 Test accuracy: 0.9676\n",
      "38 Test accuracy: 0.9681\n",
      "39 Test accuracy: 0.9672\n",
      "40 Test accuracy: 0.9713\n",
      "41 Test accuracy: 0.9703\n",
      "42 Test accuracy: 0.97\n",
      "43 Test accuracy: 0.9711\n",
      "44 Test accuracy: 0.9707\n",
      "45 Test accuracy: 0.97\n",
      "46 Test accuracy: 0.9716\n",
      "47 Test accuracy: 0.9709\n",
      "48 Test accuracy: 0.9715\n",
      "49 Test accuracy: 0.9725\n",
      "50 Test accuracy: 0.9723\n",
      "51 Test accuracy: 0.9724\n",
      "52 Test accuracy: 0.9734\n",
      "53 Test accuracy: 0.9715\n",
      "54 Test accuracy: 0.9725\n",
      "55 Test accuracy: 0.9727\n",
      "56 Test accuracy: 0.9731\n",
      "57 Test accuracy: 0.9721\n",
      "58 Test accuracy: 0.9742\n",
      "59 Test accuracy: 0.9743\n",
      "60 Test accuracy: 0.975\n",
      "61 Test accuracy: 0.9735\n",
      "62 Test accuracy: 0.9746\n",
      "63 Test accuracy: 0.9736\n",
      "64 Test accuracy: 0.9751\n",
      "65 Test accuracy: 0.9744\n",
      "66 Test accuracy: 0.9751\n",
      "67 Test accuracy: 0.9752\n",
      "68 Test accuracy: 0.974\n",
      "69 Test accuracy: 0.9757\n",
      "70 Test accuracy: 0.9758\n",
      "71 Test accuracy: 0.9751\n",
      "72 Test accuracy: 0.9755\n",
      "73 Test accuracy: 0.9751\n",
      "74 Test accuracy: 0.9763\n",
      "75 Test accuracy: 0.976\n",
      "76 Test accuracy: 0.977\n",
      "77 Test accuracy: 0.9764\n",
      "78 Test accuracy: 0.9761\n",
      "79 Test accuracy: 0.9764\n",
      "80 Test accuracy: 0.975\n",
      "81 Test accuracy: 0.977\n",
      "82 Test accuracy: 0.9771\n",
      "83 Test accuracy: 0.9752\n",
      "84 Test accuracy: 0.9771\n",
      "85 Test accuracy: 0.9763\n",
      "86 Test accuracy: 0.977\n",
      "87 Test accuracy: 0.9762\n",
      "88 Test accuracy: 0.9762\n",
      "89 Test accuracy: 0.9775\n",
      "90 Test accuracy: 0.9766\n",
      "91 Test accuracy: 0.9772\n",
      "92 Test accuracy: 0.976\n",
      "93 Test accuracy: 0.9773\n",
      "94 Test accuracy: 0.9768\n",
      "95 Test accuracy: 0.9785\n",
      "96 Test accuracy: 0.9764\n",
      "97 Test accuracy: 0.9774\n",
      "98 Test accuracy: 0.9746\n",
      "99 Test accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(mnist.test.labels) // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
