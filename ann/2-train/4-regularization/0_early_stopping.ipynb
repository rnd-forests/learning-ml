{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "Early stopping is a method to avoid overfitting the training set. The general idea is interrupting the training process when its performance on the validation set starts dropping.\n",
    "\n",
    "A simple way to implement Early Stopping in TensorFlow is to evaluate the model on a validation set at regular intervals (for example, every 50 steps), and save the best model if the current model outperforms the previous best one. Count the number of steps since the last best snapshot was saved, and interrupt training when this number reaches a limit.\n",
    "\n",
    "Early Stopping presents better performance when using with other regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "n_inputs = 784\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.elu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xen = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xen, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0 -- Validation Accuracy: 0.916833\n",
      "Epoch: 50 -- Validation Accuracy: 0.983833\n",
      "Epoch: 100 -- Validation Accuracy: 0.984333\n",
      "Epoch: 150 -- Validation Accuracy: 0.984167\n",
      "Epoch: 200 -- Validation Accuracy: 0.984\n",
      "Epoch: 250 -- Validation Accuracy: 0.984\n",
      "Epoch: 300 -- Validation Accuracy: 0.984\n",
      "Epoch: 350 -- Validation Accuracy: 0.984\n",
      "Epoch: 400 -- Validation Accuracy: 0.984\n",
      "Epoch: 450 -- Validation Accuracy: 0.984\n",
      "Best Epoch: 100\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 500\n",
    "batch_size = 100\n",
    "\n",
    "best_epoch = None # Store the epoch with the highest accuracy score\n",
    "best_accuracy = 0.97 # Best accuracy threshold\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", validation_size=6000)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(mnist.test.labels) // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        # Evaluate the model every 50 epochs on the validation set\n",
    "        # And store the best model if available\n",
    "        if epoch % 50 == 0:\n",
    "            acc_val = accuracy.eval(feed_dict={X: mnist.validation.images, y: mnist.validation.labels})\n",
    "            print(\"Epoch:\", epoch, \"--\", \"Validation Accuracy:\", acc_val)\n",
    "            if acc_val > best_accuracy:\n",
    "                best_accuracy = acc_val\n",
    "                best_epoch = epoch\n",
    "                saver.save(sess, \"models/early_stopping/best_model.cpkt\")\n",
    "    print(\"Best Epoch:\", best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/early_stopping/best_model.cpkt\n",
      "Predicted classes: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes   : [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Restore the best model and make predictions\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/early_stopping/best_model.cpkt\")\n",
    "    X_new_scaled = mnist.test.images[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "\n",
    "    print(\"Predicted classes:\", y_pred)\n",
    "    print(\"Actual classes   :\", mnist.test.labels[:20])\n",
    "    print(accuracy_score(mnist.test.labels[:20], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
