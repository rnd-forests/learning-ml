{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run './init.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train= mnist.train.images\n",
    "y_train= mnist.train.labels\n",
    "\n",
    "X_test= mnist.test.images\n",
    "y_test= mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_steps = 500\n",
    "display_step = 10\n",
    "batch_size = 128\n",
    "\n",
    "n_inputs = 784 \n",
    "n_classes = 10 \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # Weights of convolutional layers\n",
    "    # Shape -> (filter width, filter height, no. channels, no. feature maps)\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wc3': tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "    \n",
    "    # Densely connected layer. We're using max pooling with kernel size of 2\n",
    "    # after each convolutional layer so the size will be 4 ceil(28/2/2/2)\n",
    "    'wd1': tf.Variable(tf.random_normal([4*4*64, 1024])),\n",
    "    \n",
    "    # The output layer (softmax)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# x will be in the form: (n_batches, height, width, n_channels)\n",
    "# The default input format is NHWC\n",
    "# strides[0] and strides[3] must default to 1\n",
    "def conv2d(X, W, strides=1):\n",
    "    X = tf.nn.conv2d(X, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    return tf.nn.relu(X)\n",
    "\n",
    "\n",
    "def maxpool2d(X, k=2):\n",
    "    return tf.nn.max_pool(X, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def conv_net(X, weights):\n",
    "    # Reshape the input vector to 28x28 matrix\n",
    "    X = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = conv2d(X, weights['wc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    conv2 = conv2d(conv1, weights['wc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'])\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.matmul(fc1, weights['wd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    out = tf.matmul(fc1, weights['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = conv_net(X, weights)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "cost = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(cost)\n",
    "\n",
    "correct = tf.nn.in_top_k(pred, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Accuracy: 0.125\n",
      "Step: 10 Accuracy: 0.203125\n",
      "Step: 20 Accuracy: 0.34375\n",
      "Step: 30 Accuracy: 0.515625\n",
      "Step: 40 Accuracy: 0.59375\n",
      "Step: 50 Accuracy: 0.734375\n",
      "Step: 60 Accuracy: 0.632812\n",
      "Step: 70 Accuracy: 0.796875\n",
      "Step: 80 Accuracy: 0.734375\n",
      "Step: 90 Accuracy: 0.757812\n",
      "Step: 100 Accuracy: 0.78125\n",
      "Step: 110 Accuracy: 0.8125\n",
      "Step: 120 Accuracy: 0.828125\n",
      "Step: 130 Accuracy: 0.867188\n",
      "Step: 140 Accuracy: 0.867188\n",
      "Step: 150 Accuracy: 0.851562\n",
      "Step: 160 Accuracy: 0.828125\n",
      "Step: 170 Accuracy: 0.851562\n",
      "Step: 180 Accuracy: 0.890625\n",
      "Step: 190 Accuracy: 0.875\n",
      "Step: 200 Accuracy: 0.921875\n",
      "Step: 210 Accuracy: 0.914062\n",
      "Step: 220 Accuracy: 0.851562\n",
      "Step: 230 Accuracy: 0.84375\n",
      "Step: 240 Accuracy: 0.914062\n",
      "Step: 250 Accuracy: 0.84375\n",
      "Step: 260 Accuracy: 0.882812\n",
      "Step: 270 Accuracy: 0.882812\n",
      "Step: 280 Accuracy: 0.929688\n",
      "Step: 290 Accuracy: 0.90625\n",
      "Step: 300 Accuracy: 0.9375\n",
      "Step: 310 Accuracy: 0.9375\n",
      "Step: 320 Accuracy: 0.945312\n",
      "Step: 330 Accuracy: 0.867188\n",
      "Step: 340 Accuracy: 0.867188\n",
      "Step: 350 Accuracy: 0.90625\n",
      "Step: 360 Accuracy: 0.898438\n",
      "Step: 370 Accuracy: 0.875\n",
      "Step: 380 Accuracy: 0.90625\n",
      "Step: 390 Accuracy: 0.929688\n",
      "Step: 400 Accuracy: 0.9375\n",
      "Step: 410 Accuracy: 0.9375\n",
      "Step: 420 Accuracy: 0.960938\n",
      "Step: 430 Accuracy: 0.90625\n",
      "Step: 440 Accuracy: 0.9375\n",
      "Step: 450 Accuracy: 0.890625\n",
      "Step: 460 Accuracy: 0.953125\n",
      "Step: 470 Accuracy: 0.914062\n",
      "Step: 480 Accuracy: 0.9375\n",
      "Step: 490 Accuracy: 0.921875\n",
      "Step: 500 Accuracy: 0.921875\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1, n_steps+1):\n",
    "        batch_x, batch_y = random_batch(X_train, y_train, batch_size)\n",
    "        sess.run(training_op, feed_dict={X: batch_x, y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            acc = sess.run( accuracy, feed_dict={X: batch_x, y: batch_y})\n",
    "            print('Step:', step, 'Accuracy:', acc)\n",
    "            \n",
    "    test_acc = sess.run(accuracy, feed_dict={X: mnist.test.images[:100],y: mnist.test.labels[:100]})\n",
    "    print(\"Test Accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
